{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.858668Z",
     "start_time": "2025-12-02T17:46:42.855670Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.885444Z",
     "start_time": "2025-12-02T17:46:42.860728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.set_num_threads(torch.get_num_threads())  # typically max threads\n",
    "torch.set_num_interop_threads(torch.get_num_interop_threads())"
   ],
   "id": "2c04492fc1a04e72",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.934660Z",
     "start_time": "2025-12-02T17:46:42.887951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HairTypeCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A small Convolutional Neural Network for identifying hair types\n",
    "    from 200x200 color images (e.g., curly vs. straight).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input: 3 x 200 x 200 hair image\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # After conv and pooling:\n",
    "        # 200 → 198 → pooled to 99\n",
    "        flattened_size = 32 * 99 * 99\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()   # binary hair-type output (0 or 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.conv1(x))\n",
    "\n",
    "\n",
    "        x = self.pool(x)\n",
    "\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HairTypeCNN().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "criterion = nn.BCELoss()\n"
   ],
   "id": "fe77de9f173df68b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.951585Z",
     "start_time": "2025-12-02T17:46:42.938542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 200, 200))"
   ],
   "id": "cb85db2d517be6f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 198, 198]             896\n",
      "              ReLU-2         [-1, 32, 198, 198]               0\n",
      "         MaxPool2d-3           [-1, 32, 99, 99]               0\n",
      "            Linear-4                   [-1, 64]      20,072,512\n",
      "              ReLU-5                   [-1, 64]               0\n",
      "            Linear-6                    [-1, 1]              65\n",
      "           Sigmoid-7                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 20,073,473\n",
      "Trainable params: 20,073,473\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 21.54\n",
      "Params size (MB): 76.57\n",
      "Estimated Total Size (MB): 98.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.957129Z",
     "start_time": "2025-12-02T17:46:42.953005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])"
   ],
   "id": "404f2a487ffa9ac2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.966462Z",
     "start_time": "2025-12-02T17:46:42.960874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ImageFolder(\n",
    "    \"C:/Users/mm3le/PycharmProjects/ml-zoomcamp/08-Neural-Networks-HW/data/train\",\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "5fabb70f0225c643",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:46:42.972243Z",
     "start_time": "2025-12-02T17:46:42.968823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_dataset = ImageFolder(\"C:/Users/mm3le/PycharmProjects/ml-zoomcamp/08-Neural-Networks-HW/data/test\",\n",
    "                                 transform=train_transforms)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "6edc42ce63609653",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:58:00.595435Z",
     "start_time": "2025-12-02T17:56:59.031285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ],
   "id": "bcee7140fc845954",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1798, Acc: 0.4875, Val Loss: 0.7692, Val Acc: 0.4876\n",
      "Epoch 2/10, Loss: 0.1610, Acc: 0.4875, Val Loss: 0.7847, Val Acc: 0.4876\n",
      "Epoch 3/10, Loss: 0.1376, Acc: 0.4888, Val Loss: 1.0123, Val Acc: 0.4876\n",
      "Epoch 4/10, Loss: 0.1026, Acc: 0.4875, Val Loss: 0.8488, Val Acc: 0.4876\n",
      "Epoch 5/10, Loss: 0.0456, Acc: 0.4888, Val Loss: 0.9437, Val Acc: 0.4876\n",
      "Epoch 6/10, Loss: 0.0309, Acc: 0.4875, Val Loss: 0.9498, Val Acc: 0.4876\n",
      "Epoch 7/10, Loss: 0.0231, Acc: 0.4888, Val Loss: 0.9089, Val Acc: 0.4925\n",
      "Epoch 8/10, Loss: 0.0172, Acc: 0.4888, Val Loss: 0.9695, Val Acc: 0.4925\n",
      "Epoch 9/10, Loss: 0.0138, Acc: 0.4900, Val Loss: 1.0046, Val Acc: 0.4925\n",
      "Epoch 10/10, Loss: 0.0118, Acc: 0.4913, Val Loss: 1.0972, Val Acc: 0.4925\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:58:25.566061Z",
     "start_time": "2025-12-02T17:58:25.562213Z"
    }
   },
   "cell_type": "code",
   "source": "print(np.median(history['acc']), np.std(history['acc']))\n",
   "id": "856a480e97106901",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48875 0.0011792476415070838\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T17:59:40.039414Z",
     "start_time": "2025-12-02T17:59:40.036413Z"
    }
   },
   "cell_type": "code",
   "source": "print(np.average(history['val_loss']))",
   "id": "9d5bd185984937c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9288506045566862 0.0024373032266499176\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:00:40.576310Z",
     "start_time": "2025-12-02T18:00:40.573427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "last5_avg = np.mean(history['val_acc'][-5:])\n",
    "print(last5_avg)"
   ],
   "id": "4a940562f8ef6d49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4915422885572139\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
